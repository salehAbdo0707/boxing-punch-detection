{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Necessary Libraries and Initializing our Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "from scipy.stats import linregress\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "mdphands = mp.solutions.hands\n",
    "hands = mdphands.Hands()\n",
    "mdpdrawing = mp.solutions.drawing_utils\n",
    "area_for_hands = [[], []]\n",
    "counter = 0\n",
    "coords_for_leftHand = [np.array([0, 0]), np.array([0, 0])]\n",
    "coords_for_rightHand = [np.array([0, 0]), np.array([0, 0])]\n",
    "ydampingfactor = 0.15\n",
    "vid = cv2.VideoCapture(0)\n",
    "fps = vid.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('output.avi', fourcc, fps, (int(vid.get(3)), int(vid.get(4))))\n",
    "overlay_box_size = 200  \n",
    "fist_img = cv2.imread('fist.png')\n",
    "fist_img = cv2.resize(fist_img, (50, 50))\n",
    "punch_count = 0\n",
    "previous_fist_state = False\n",
    "fist_start_time = None\n",
    "fist_delay = 1.4  # in seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hand(hand_landmarks):  # Function to detect right or left hand\n",
    "    # Calculate the center of the hand\n",
    "    center_x = sum([lm.x for lm in hand_landmarks.landmark]) / len(hand_landmarks.landmark)\n",
    "    center_y = sum([lm.y for lm in hand_landmarks.landmark]) / len(hand_landmarks.landmark)\n",
    "    # Calculate the wrist position\n",
    "    wrist_x = hand_landmarks.landmark[0].x\n",
    "    wrist_y = hand_landmarks.landmark[0].y\n",
    "    # If the wrist is to the left of the center, it's a right hand\n",
    "    if wrist_x < center_x:\n",
    "        return \"Right\"\n",
    "    else:\n",
    "        return \"Left\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_fist(hand_landmarks): # Function to detect fist\n",
    "    # Check if the thumb is close to the palm\n",
    "    thumb_tip = hand_landmarks.landmark[4]\n",
    "    thumb_ip = hand_landmarks.landmark[3]\n",
    "    thumb_mcp = hand_landmarks.landmark[2]\n",
    "    thumb_cmc = hand_landmarks.landmark[1]\n",
    "\n",
    "    if (\n",
    "        np.linalg.norm([thumb_tip.x - thumb_ip.x, thumb_tip.y - thumb_ip.y, thumb_tip.z - thumb_ip.z]) < 0.1\n",
    "        and np.linalg.norm([thumb_ip.x - thumb_mcp.x, thumb_ip.y - thumb_mcp.y, thumb_ip.z - thumb_mcp.z]) < 0.1\n",
    "        and np.linalg.norm([thumb_mcp.x - thumb_cmc.x, thumb_mcp.y - thumb_cmc.y, thumb_mcp.z - thumb_cmc.z]) < 0.1\n",
    "    ):\n",
    "        # Check if the other fingers are close to the palm\n",
    "        for finger_id in [8, 12, 16, 20]:\n",
    "            finger_tip = hand_landmarks.landmark[finger_id]\n",
    "            finger_pip = hand_landmarks.landmark[finger_id - 2]\n",
    "            finger_mcp = hand_landmarks.landmark[finger_id - 3]\n",
    "\n",
    "            if (\n",
    "                np.linalg.norm([finger_tip.x - finger_pip.x, finger_tip.y - finger_pip.y, finger_tip.z - finger_pip.z]) > 0.2\n",
    "                or np.linalg.norm([finger_pip.x - finger_mcp.x, finger_pip.y - finger_mcp.y, finger_pip.z - finger_mcp.z]) > 0.2\n",
    "            ):\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_hand(image, hand_landmarks): # Function to segment hand\n",
    "    mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "    points = []\n",
    "    for lm in hand_landmarks.landmark:\n",
    "        h, w, _ = image.shape\n",
    "        cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "        points.append((cx, cy))\n",
    "\n",
    "    points = np.array(points, dtype=np.int32)\n",
    "    cv2.fillPoly(mask, [points], 255)\n",
    "    segmented_hand = cv2.bitwise_and(image, image, mask=mask)\n",
    "    return segmented_hand, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 125\u001b[0m\n\u001b[0;32m    122\u001b[0m     area_for_hands[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# Write the frame to the output video file\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m \u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m cv2\u001b[38;5;241m.\u001b[39mnamedWindow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScreen\u001b[39m\u001b[38;5;124m'\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mWINDOW_NORMAL)\n\u001b[0;32m    129\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScreen\u001b[39m\u001b[38;5;124m\"\u001b[39m, img)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while vid.isOpened(): # Main loop\n",
    "    success, img = vid.read()\n",
    "\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    img = cv2.flip(img, 2)\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img.flags.writeable = False\n",
    "    results = hands.process(img)\n",
    "    img.flags.writeable = True\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    overlay_box_top_left = (img.shape[1] - overlay_box_size - 10, 10)  # Top right corner of the screen\n",
    "\n",
    "    # Draw the overlay box\n",
    "    cv2.rectangle(\n",
    "        img, overlay_box_top_left,\n",
    "        (overlay_box_top_left[0] + overlay_box_size, overlay_box_top_left[1] + overlay_box_size),\n",
    "        (255, 255, 255), -1\n",
    "    )\n",
    "\n",
    "    fist_detected = False\n",
    "    fist_label = \"\"\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            handedness = get_hand(hand_landmarks)\n",
    "\n",
    "            if handedness == \"Left\":\n",
    "                handedness_id = 0\n",
    "                hand_positions = coords_for_leftHand\n",
    "            else:\n",
    "                handedness_id = 1\n",
    "                hand_positions = coords_for_rightHand\n",
    "\n",
    "            # Segment the hand\n",
    "            segmented_hand, hand_mask = segment_hand(img, hand_landmarks)\n",
    "\n",
    "            # Find contours\n",
    "            contours, _ = cv2.findContours(hand_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            if contours:\n",
    "                largest_contour = max(contours, key=cv2.contourArea)\n",
    "                x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "                hand_bbox = np.array([x, y, x + w, y + h])\n",
    "\n",
    "                # Update hand positions using the calculated bounding box\n",
    "                hand_positions[0] = np.array([hand_bbox[0], hand_bbox[1]])\n",
    "                hand_positions[1] = np.array([hand_bbox[2], hand_bbox[3]])\n",
    "\n",
    "                current_top_left_point_hand = hand_positions[0] + (np.array([hand_bbox[0], hand_bbox[1]]) - hand_positions[0]) * ydampingfactor\n",
    "                current_bottom_right_point_hand = hand_positions[1] + (np.array([hand_bbox[2], hand_bbox[3]]) - hand_positions[1]) * ydampingfactor\n",
    "\n",
    "                max_width_hand = (current_bottom_right_point_hand[0] - current_top_left_point_hand[0])\n",
    "                max_height_hand = (current_bottom_right_point_hand[1] - current_top_left_point_hand[1])\n",
    "                area_for_hands[handedness_id] += [max_width_hand * max_height_hand]\n",
    "\n",
    "                cv2.rectangle(\n",
    "                    img, (int(current_top_left_point_hand[0]), int(current_top_left_point_hand[1])),\n",
    "                    (int(current_bottom_right_point_hand[0]), int(current_bottom_right_point_hand[1])), (255, 255, 255),\n",
    "                    2\n",
    "                )\n",
    "\n",
    "                hand_positions[0] = current_top_left_point_hand\n",
    "                hand_positions[1] = current_bottom_right_point_hand\n",
    "\n",
    "                # Draw landmarks on the segmented hand image\n",
    "            mdpdrawing.draw_landmarks(img, hand_landmarks, mdphands.HAND_CONNECTIONS)\n",
    "\n",
    "            if is_fist(hand_landmarks):\n",
    "                    fist_detected = True\n",
    "                    fist_label = f\"{handedness} Fist\"\n",
    "\n",
    "    # Punch counting logic with delay\n",
    "    current_time = time.time()\n",
    "    if fist_detected:\n",
    "        if not previous_fist_state:\n",
    "            fist_start_time = current_time\n",
    "        elif current_time - fist_start_time >= fist_delay:\n",
    "            punch_count += 1\n",
    "            fist_start_time = current_time  # We must reset the start time to avoid multiple counts for the same punch\n",
    "    previous_fist_state = fist_detected\n",
    "\n",
    "\n",
    "    if fist_detected:\n",
    "        # Calculate the center coordinates of the overlay box\n",
    "        overlay_center_x = overlay_box_top_left[0] + overlay_box_size // 2\n",
    "        overlay_center_y = overlay_box_top_left[1] + overlay_box_size // 2\n",
    "\n",
    "        # Calculate the top-left corner coordinates to position the fist_img at the center\n",
    "        fist_x_min = overlay_center_x - fist_img.shape[1] // 2\n",
    "        fist_y_min = overlay_center_y - fist_img.shape[0] // 2\n",
    "\n",
    "        # Replace the portion of the image with the fist image\n",
    "        img[fist_y_min:fist_y_min+fist_img.shape[0], fist_x_min:fist_x_min+fist_img.shape[1]] = fist_img\n",
    "\n",
    "        cv2.putText(img, fist_label, (overlay_box_top_left[0] + 10, overlay_box_top_left[1] + 30), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 20, 147), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Display punch count\n",
    "    cv2.putText(img, f\"Punches: {punch_count}\", (10, 30), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    if len(area_for_hands[0]) >= 5 and len(area_for_hands[1]) >= 5:\n",
    "        left = area_for_hands[0][-5:]\n",
    "        right = area_for_hands[1][-5:]\n",
    "\n",
    "        x = list(range(5))\n",
    "\n",
    "        left_hand_slope, _, _, _, _ = linregress(x, left)\n",
    "        right_hand_slope, _, _, _, _ = linregress(x, right)\n",
    "\n",
    "        if left_hand_slope > 600:\n",
    "            print(f\"Left {counter}: {left_hand_slope}\")\n",
    "            counter += 1\n",
    "        elif right_hand_slope > 600: \n",
    "            print(f\"Right {counter}: {right_hand_slope}\")\n",
    "            counter += 1\n",
    "\n",
    "        area_for_hands[0] = []\n",
    "        area_for_hands[1] = []\n",
    "\n",
    "    # Write the frame to the output video file\n",
    "    out.write(img)\n",
    "\n",
    "    cv2.namedWindow('Screen', cv2.WINDOW_NORMAL)\n",
    "\n",
    "    cv2.imshow(\"Screen\", img)\n",
    "\n",
    "    pressed_key = cv2.waitKey(8)\n",
    "    if pressed_key == ord('q'):\n",
    "        vid.release()\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
